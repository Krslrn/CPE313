{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "1ef7c1ac-e93a-4a79-adfe-c4a4ea44f1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "662               8                     167             106              46   \n",
              "324               2                     112              75              32   \n",
              "494               3                      80               0               0   \n",
              "278               5                     114              74               0   \n",
              "353               1                      90              62              12   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "662      231  37.6              0.165   43             1  \n",
              "324        0  35.7              0.148   21             0  \n",
              "494        0   0.0              0.174   22             0  \n",
              "278        0  24.9              0.744   57             0  \n",
              "353       43  27.2              0.580   24             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d46f6a3f-fc0b-4aa8-b186-f6e4ce69ef8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>8</td>\n",
              "      <td>167</td>\n",
              "      <td>106</td>\n",
              "      <td>46</td>\n",
              "      <td>231</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.165</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>2</td>\n",
              "      <td>112</td>\n",
              "      <td>75</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>35.7</td>\n",
              "      <td>0.148</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.174</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>5</td>\n",
              "      <td>114</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.9</td>\n",
              "      <td>0.744</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>62</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "      <td>27.2</td>\n",
              "      <td>0.580</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d46f6a3f-fc0b-4aa8-b186-f6e4ce69ef8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d46f6a3f-fc0b-4aa8-b186-f6e4ce69ef8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d46f6a3f-fc0b-4aa8-b186-f6e4ce69ef8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4820877-0b37-42a0-b7f9-bb7799bbae7d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4820877-0b37-42a0-b7f9-bb7799bbae7d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4820877-0b37-42a0-b7f9-bb7799bbae7d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36150363-6b71-4bd2-a9e7-62b5ca49d2e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa59df1e-ea29-4f56-f8f3-684e4841e31c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb1ef1e-0343-40de-f772-2f0ca2d7bee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210eab9-85ad-4373-c15f-444a85984128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 16ms/step - loss: 0.7618 - accuracy: 0.5295 - val_loss: 0.7875 - val_accuracy: 0.5104\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.5712 - val_loss: 0.7504 - val_accuracy: 0.5781\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.6024 - val_loss: 0.7210 - val_accuracy: 0.5938\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.6181 - val_loss: 0.6973 - val_accuracy: 0.5990\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.6181 - val_loss: 0.6781 - val_accuracy: 0.5938\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6343 - accuracy: 0.6215 - val_loss: 0.6620 - val_accuracy: 0.6146\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6203 - accuracy: 0.6285 - val_loss: 0.6484 - val_accuracy: 0.6250\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6458 - val_loss: 0.6366 - val_accuracy: 0.6302\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.6545 - val_loss: 0.6264 - val_accuracy: 0.6406\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.6667 - val_loss: 0.6174 - val_accuracy: 0.6354\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.6719 - val_loss: 0.6094 - val_accuracy: 0.6458\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5725 - accuracy: 0.6788 - val_loss: 0.6024 - val_accuracy: 0.6615\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.6840 - val_loss: 0.5960 - val_accuracy: 0.6615\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.6858 - val_loss: 0.5903 - val_accuracy: 0.6771\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.6927 - val_loss: 0.5852 - val_accuracy: 0.6875\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.6944 - val_loss: 0.5806 - val_accuracy: 0.6927\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.6962 - val_loss: 0.5763 - val_accuracy: 0.6927\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.6997 - val_loss: 0.5724 - val_accuracy: 0.6927\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7049 - val_loss: 0.5689 - val_accuracy: 0.6979\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.7049 - val_loss: 0.5655 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7083 - val_loss: 0.5624 - val_accuracy: 0.6979\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7066 - val_loss: 0.5594 - val_accuracy: 0.6979\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7066 - val_loss: 0.5567 - val_accuracy: 0.6979\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7066 - val_loss: 0.5541 - val_accuracy: 0.6927\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7083 - val_loss: 0.5516 - val_accuracy: 0.7031\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7118 - val_loss: 0.5493 - val_accuracy: 0.7031\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.7205 - val_loss: 0.5472 - val_accuracy: 0.7083\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7257 - val_loss: 0.5451 - val_accuracy: 0.7135\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7257 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7378 - val_loss: 0.5413 - val_accuracy: 0.7135\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7361 - val_loss: 0.5396 - val_accuracy: 0.7188\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7431 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7431 - val_loss: 0.5363 - val_accuracy: 0.7240\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7483 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7500 - val_loss: 0.5335 - val_accuracy: 0.7292\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7500 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7517 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7517 - val_loss: 0.5296 - val_accuracy: 0.7292\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7500 - val_loss: 0.5284 - val_accuracy: 0.7292\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7517 - val_loss: 0.5273 - val_accuracy: 0.7344\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7552 - val_loss: 0.5262 - val_accuracy: 0.7240\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7569 - val_loss: 0.5252 - val_accuracy: 0.7240\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7587 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7587 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7604 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7639 - val_loss: 0.5212 - val_accuracy: 0.7448\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7639 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7604 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7604 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7622 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7656 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7674 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7691 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7691 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7691 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7691 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7691 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7691 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7691 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7726 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7691 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7708 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7726 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7691 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7708 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7708 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7708 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7708 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7708 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7708 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7708 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5079 - val_accuracy: 0.7656\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cccaa27c-65bf-4b89-b146-5d26e9244199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e110911f-d5ef-4a79-bf40-4eb8d53e921e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65582037],\n",
              "       [0.6507114 ],\n",
              "       [0.32304847],\n",
              "       [0.21720952],\n",
              "       [0.1633364 ],\n",
              "       [0.4551786 ],\n",
              "       [0.02752979],\n",
              "       [0.38203385],\n",
              "       [0.89780146],\n",
              "       [0.17257361]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2444a99d-9d80-4c28-9e16-6536a0026adc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65582037],\n",
              "       [0.6507114 ],\n",
              "       [0.32304847],\n",
              "       [0.21720952],\n",
              "       [0.1633364 ],\n",
              "       [0.4551786 ],\n",
              "       [0.02752979],\n",
              "       [0.38203385],\n",
              "       [0.89780146],\n",
              "       [0.17257361]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=200)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "48fJvxESAo0x",
        "outputId": "f7d3c21a-e799-450b-e2c5-36e5e82d0e86"
      },
      "id": "48fJvxESAo0x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_rf = rf.predict(X_test)\n",
        "y_pred_prob_rf = rf.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no5k7nhaBUA5",
        "outputId": "a271dfd8-8efb-49e3-92a4-0cad6f58cdf1"
      },
      "id": "no5k7nhaBUA5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.760\n",
            "roc-auc is 0.818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "770d8334-3075-4a9c-c828-831cad93f8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.760\n",
            "roc-auc is 0.818\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040899be-2b09-42e7-b8c0-4736cf0b1269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "13b0d677-098a-4a93-ef59-d80098f35587"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ce35e04a7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#type your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My interpretation on the results of train and validation loss is that the model should have further training, thus adding more epoch may result into better or worse. Also, the results shows it is underfitting since the both losses is high creating wider gap each epoch."
      ],
      "metadata": {
        "id": "jTZS0A8bB10Z"
      },
      "id": "jTZS0A8bB10Z"
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with 6 nodes\n",
        "#Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "model_supple = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"sigmoid\"),\n",
        "    Dense(2, activation=\"relu\")\n",
        "])"
      ],
      "metadata": {
        "id": "YVAOeluKCZdZ"
      },
      "id": "YVAOeluKCZdZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbDY1M6XCmjZ",
        "outputId": "5b5e7491-7e5e-4079-d6f9-91c9227537a6"
      },
      "id": "pbDY1M6XCmjZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68 (272.00 Byte)\n",
            "Trainable params: 68 (272.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_supple.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_supple.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njEyvuP3CtGx",
        "outputId": "e65c8f49-0a82-49f8-8520-db947d207d92"
      },
      "id": "njEyvuP3CtGx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 6.6705 - accuracy: 0.6545 - val_loss: 6.5424 - val_accuracy: 0.6406\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 6.0002 - accuracy: 0.6545 - val_loss: 5.4796 - val_accuracy: 0.6406\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 5.5249 - accuracy: 0.6528 - val_loss: 3.5747 - val_accuracy: 0.6406\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.2684 - accuracy: 0.6545 - val_loss: 3.3410 - val_accuracy: 0.6406\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.2098 - accuracy: 0.6545 - val_loss: 3.4664 - val_accuracy: 0.6406\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0724 - accuracy: 0.6545 - val_loss: 3.1567 - val_accuracy: 0.6406\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0379 - accuracy: 0.6545 - val_loss: 3.1418 - val_accuracy: 0.6406\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.0258 - accuracy: 0.6545 - val_loss: 3.1325 - val_accuracy: 0.6406\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.0175 - accuracy: 0.6545 - val_loss: 3.1250 - val_accuracy: 0.6406\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9997 - accuracy: 0.6545 - val_loss: 3.1170 - val_accuracy: 0.6406\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9832 - accuracy: 0.6545 - val_loss: 3.1115 - val_accuracy: 0.6406\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9775 - accuracy: 0.6545 - val_loss: 3.1070 - val_accuracy: 0.6406\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9723 - accuracy: 0.6545 - val_loss: 3.1018 - val_accuracy: 0.6406\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9684 - accuracy: 0.6545 - val_loss: 3.0990 - val_accuracy: 0.6406\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9649 - accuracy: 0.6545 - val_loss: 3.0970 - val_accuracy: 0.6406\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9615 - accuracy: 0.6545 - val_loss: 3.0980 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9589 - accuracy: 0.6545 - val_loss: 3.1213 - val_accuracy: 0.6406\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9567 - accuracy: 0.6545 - val_loss: 3.1180 - val_accuracy: 0.6406\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9541 - accuracy: 0.6545 - val_loss: 3.1158 - val_accuracy: 0.6406\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9524 - accuracy: 0.6545 - val_loss: 3.1134 - val_accuracy: 0.6406\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9504 - accuracy: 0.6545 - val_loss: 3.1112 - val_accuracy: 0.6406\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9487 - accuracy: 0.6545 - val_loss: 3.1094 - val_accuracy: 0.6406\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9472 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9456 - accuracy: 0.6545 - val_loss: 3.1059 - val_accuracy: 0.6406\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.0134 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9322 - accuracy: 0.6545 - val_loss: 3.0685 - val_accuracy: 0.6406\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9265 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9249 - accuracy: 0.6545 - val_loss: 3.0959 - val_accuracy: 0.6406\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9239 - accuracy: 0.6545 - val_loss: 3.0948 - val_accuracy: 0.6406\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9228 - accuracy: 0.6545 - val_loss: 3.0939 - val_accuracy: 0.6406\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9221 - accuracy: 0.6545 - val_loss: 3.0930 - val_accuracy: 0.6406\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9211 - accuracy: 0.6545 - val_loss: 3.0922 - val_accuracy: 0.6406\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9204 - accuracy: 0.6545 - val_loss: 3.0914 - val_accuracy: 0.6406\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9198 - accuracy: 0.6545 - val_loss: 3.0908 - val_accuracy: 0.6406\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9190 - accuracy: 0.6545 - val_loss: 3.0901 - val_accuracy: 0.6406\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9184 - accuracy: 0.6545 - val_loss: 3.0894 - val_accuracy: 0.6406\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9177 - accuracy: 0.6545 - val_loss: 3.0887 - val_accuracy: 0.6406\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9174 - accuracy: 0.6545 - val_loss: 3.0882 - val_accuracy: 0.6406\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9168 - accuracy: 0.6545 - val_loss: 3.0877 - val_accuracy: 0.6406\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9164 - accuracy: 0.6545 - val_loss: 3.0873 - val_accuracy: 0.6406\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9159 - accuracy: 0.6545 - val_loss: 3.0868 - val_accuracy: 0.6406\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9153 - accuracy: 0.6545 - val_loss: 3.0863 - val_accuracy: 0.6406\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9148 - accuracy: 0.6545 - val_loss: 3.0861 - val_accuracy: 0.6406\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9144 - accuracy: 0.6545 - val_loss: 3.0859 - val_accuracy: 0.6406\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9144 - accuracy: 0.6545 - val_loss: 3.0852 - val_accuracy: 0.6406\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9141 - accuracy: 0.6545 - val_loss: 3.0847 - val_accuracy: 0.6406\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9134 - accuracy: 0.6545 - val_loss: 3.0843 - val_accuracy: 0.6406\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9132 - accuracy: 0.6545 - val_loss: 3.0841 - val_accuracy: 0.6406\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9128 - accuracy: 0.6545 - val_loss: 3.0837 - val_accuracy: 0.6406\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9125 - accuracy: 0.6545 - val_loss: 3.0834 - val_accuracy: 0.6406\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9120 - accuracy: 0.6545 - val_loss: 3.0830 - val_accuracy: 0.6406\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9121 - accuracy: 0.6545 - val_loss: 3.0829 - val_accuracy: 0.6406\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9117 - accuracy: 0.6545 - val_loss: 3.0825 - val_accuracy: 0.6406\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9115 - accuracy: 0.6545 - val_loss: 3.0823 - val_accuracy: 0.6406\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9109 - accuracy: 0.6545 - val_loss: 3.0821 - val_accuracy: 0.6406\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9106 - accuracy: 0.6545 - val_loss: 3.0816 - val_accuracy: 0.6406\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9104 - accuracy: 0.6545 - val_loss: 3.0813 - val_accuracy: 0.6406\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9098 - accuracy: 0.6545 - val_loss: 3.0812 - val_accuracy: 0.6406\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9099 - accuracy: 0.6545 - val_loss: 3.0808 - val_accuracy: 0.6406\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9096 - accuracy: 0.6545 - val_loss: 3.0805 - val_accuracy: 0.6406\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9093 - accuracy: 0.6545 - val_loss: 3.0804 - val_accuracy: 0.6406\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9091 - accuracy: 0.6545 - val_loss: 3.0801 - val_accuracy: 0.6406\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9092 - accuracy: 0.6545 - val_loss: 3.0798 - val_accuracy: 0.6406\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9087 - accuracy: 0.6545 - val_loss: 3.0796 - val_accuracy: 0.6406\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9084 - accuracy: 0.6545 - val_loss: 3.0794 - val_accuracy: 0.6406\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9079 - accuracy: 0.6545 - val_loss: 3.0793 - val_accuracy: 0.6406\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9080 - accuracy: 0.6545 - val_loss: 3.0790 - val_accuracy: 0.6406\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9076 - accuracy: 0.6545 - val_loss: 3.0789 - val_accuracy: 0.6406\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9077 - accuracy: 0.6545 - val_loss: 3.0786 - val_accuracy: 0.6406\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9073 - accuracy: 0.6545 - val_loss: 3.0785 - val_accuracy: 0.6406\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9072 - accuracy: 0.6545 - val_loss: 3.0783 - val_accuracy: 0.6406\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9070 - accuracy: 0.6545 - val_loss: 3.0782 - val_accuracy: 0.6406\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9073 - accuracy: 0.6545 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9067 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9063 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9060 - accuracy: 0.6545 - val_loss: 3.0774 - val_accuracy: 0.6406\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9060 - accuracy: 0.6545 - val_loss: 3.0772 - val_accuracy: 0.6406\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9057 - accuracy: 0.6545 - val_loss: 3.0771 - val_accuracy: 0.6406\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9055 - accuracy: 0.6545 - val_loss: 3.0769 - val_accuracy: 0.6406\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9056 - accuracy: 0.6545 - val_loss: 3.0769 - val_accuracy: 0.6406\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9054 - accuracy: 0.6545 - val_loss: 3.0767 - val_accuracy: 0.6406\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9052 - accuracy: 0.6545 - val_loss: 3.0767 - val_accuracy: 0.6406\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9053 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9050 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9050 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9050 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.9048 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.9044 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9046 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9041 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9042 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9042 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9039 - accuracy: 0.6545 - val_loss: 3.0752 - val_accuracy: 0.6406\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9039 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9035 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9037 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9035 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9032 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9035 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9030 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9030 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9032 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9028 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9024 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9026 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9024 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9027 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9024 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9024 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9023 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9019 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9020 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9018 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9019 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9018 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9017 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9017 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9015 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9013 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9016 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9013 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9013 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9011 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9016 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9012 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9008 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9008 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9008 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9008 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9009 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9007 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9010 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9007 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9009 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9007 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9002 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9005 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9002 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9004 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9005 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9003 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9000 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9000 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8998 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9005 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9000 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9000 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8997 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8998 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8996 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8996 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8998 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8999 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8998 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8997 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8997 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9000 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8998 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8997 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8996 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8991 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8996 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8997 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8995 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8991 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8991 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8989 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8991 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8989 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8989 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8992 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8991 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8989 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8990 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8988 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8989 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8993 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8986 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8987 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8985 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0713 - val_accuracy: 0.6406\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8984 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8981 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8982 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0714 - val_accuracy: 0.6406\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8980 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8976 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8977 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0715 - val_accuracy: 0.6406\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8970 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8973 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8978 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8970 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8974 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8975 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8970 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8972 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0716 - val_accuracy: 0.6406\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8967 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8971 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8969 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8970 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8965 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8970 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0717 - val_accuracy: 0.6406\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8966 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8968 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8963 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8964 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0718 - val_accuracy: 0.6406\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8960 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8959 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0719 - val_accuracy: 0.6406\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8961 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8962 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8958 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8950 - accuracy: 0.6545 - val_loss: 3.0720 - val_accuracy: 0.6406\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8955 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8957 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8950 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8956 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8950 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0721 - val_accuracy: 0.6406\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8953 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0722 - val_accuracy: 0.6406\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8952 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8954 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8951 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8950 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8949 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8947 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0723 - val_accuracy: 0.6406\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0724 - val_accuracy: 0.6406\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8950 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8948 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8945 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0726 - val_accuracy: 0.6406\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8942 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0725 - val_accuracy: 0.6406\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8944 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8946 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8939 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8940 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0727 - val_accuracy: 0.6406\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8937 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0728 - val_accuracy: 0.6406\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8938 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8941 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8936 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0729 - val_accuracy: 0.6406\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0731 - val_accuracy: 0.6406\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0730 - val_accuracy: 0.6406\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8930 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 2.8935 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8930 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8932 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8933 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8934 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0732 - val_accuracy: 0.6406\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0734 - val_accuracy: 0.6406\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8930 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8930 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8931 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0733 - val_accuracy: 0.6406\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0736 - val_accuracy: 0.6406\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8927 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8928 - accuracy: 0.6545 - val_loss: 3.0752 - val_accuracy: 0.6406\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8924 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0735 - val_accuracy: 0.6406\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8925 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8922 - accuracy: 0.6545 - val_loss: 3.0737 - val_accuracy: 0.6406\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0738 - val_accuracy: 0.6406\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8926 - accuracy: 0.6545 - val_loss: 3.0742 - val_accuracy: 0.6406\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8916 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8930 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8916 - accuracy: 0.6545 - val_loss: 3.0739 - val_accuracy: 0.6406\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0741 - val_accuracy: 0.6406\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0740 - val_accuracy: 0.6406\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8916 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8920 - accuracy: 0.6545 - val_loss: 3.0743 - val_accuracy: 0.6406\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8919 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8917 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0761 - val_accuracy: 0.6406\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8916 - accuracy: 0.6545 - val_loss: 3.0769 - val_accuracy: 0.6406\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8915 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0787 - val_accuracy: 0.6406\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8915 - accuracy: 0.6545 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8921 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8916 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8915 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8909 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8923 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0749 - val_accuracy: 0.6406\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8915 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0752 - val_accuracy: 0.6406\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0746 - val_accuracy: 0.6406\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0752 - val_accuracy: 0.6406\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0760 - val_accuracy: 0.6406\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8915 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8908 - accuracy: 0.6528 - val_loss: 3.0744 - val_accuracy: 0.6406\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8909 - accuracy: 0.6545 - val_loss: 3.0747 - val_accuracy: 0.6406\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0753 - val_accuracy: 0.6406\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0772 - val_accuracy: 0.6406\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0761 - val_accuracy: 0.6406\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0748 - val_accuracy: 0.6406\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0793 - val_accuracy: 0.6406\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0761 - val_accuracy: 0.6406\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6528 - val_loss: 3.0788 - val_accuracy: 0.6406\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8914 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8912 - accuracy: 0.6545 - val_loss: 3.0755 - val_accuracy: 0.6406\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0745 - val_accuracy: 0.6406\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0765 - val_accuracy: 0.6406\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8913 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8909 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0751 - val_accuracy: 0.6406\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0750 - val_accuracy: 0.6406\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6545 - val_loss: 3.0769 - val_accuracy: 0.6406\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0775 - val_accuracy: 0.6406\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0775 - val_accuracy: 0.6406\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8918 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0768 - val_accuracy: 0.6406\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6528 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8910 - accuracy: 0.6528 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0773 - val_accuracy: 0.6406\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0775 - val_accuracy: 0.6406\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8908 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8911 - accuracy: 0.6545 - val_loss: 3.0772 - val_accuracy: 0.6406\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0768 - val_accuracy: 0.6406\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0767 - val_accuracy: 0.6406\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0761 - val_accuracy: 0.6406\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0783 - val_accuracy: 0.6406\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6545 - val_loss: 3.0772 - val_accuracy: 0.6406\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8906 - accuracy: 0.6528 - val_loss: 3.0765 - val_accuracy: 0.6406\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0756 - val_accuracy: 0.6406\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8909 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0802 - val_accuracy: 0.6406\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6528 - val_loss: 3.0757 - val_accuracy: 0.6406\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0805 - val_accuracy: 0.6406\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0813 - val_accuracy: 0.6406\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0767 - val_accuracy: 0.6406\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0778 - val_accuracy: 0.6406\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0758 - val_accuracy: 0.6406\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0791 - val_accuracy: 0.6406\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8901 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0778 - val_accuracy: 0.6406\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0797 - val_accuracy: 0.6406\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8900 - accuracy: 0.6528 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0775 - val_accuracy: 0.6406\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0764 - val_accuracy: 0.6406\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8901 - accuracy: 0.6545 - val_loss: 3.0787 - val_accuracy: 0.6406\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8901 - accuracy: 0.6545 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8901 - accuracy: 0.6528 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8900 - accuracy: 0.6545 - val_loss: 3.0783 - val_accuracy: 0.6406\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0759 - val_accuracy: 0.6406\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0774 - val_accuracy: 0.6406\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0781 - val_accuracy: 0.6406\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8904 - accuracy: 0.6545 - val_loss: 3.0752 - val_accuracy: 0.6406\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0754 - val_accuracy: 0.6406\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8901 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8899 - accuracy: 0.6528 - val_loss: 3.0765 - val_accuracy: 0.6406\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8907 - accuracy: 0.6545 - val_loss: 3.0795 - val_accuracy: 0.6406\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0845 - val_accuracy: 0.6406\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8900 - accuracy: 0.6545 - val_loss: 3.0820 - val_accuracy: 0.6406\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0765 - val_accuracy: 0.6406\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8905 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8900 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0781 - val_accuracy: 0.6406\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0773 - val_accuracy: 0.6406\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8903 - accuracy: 0.6545 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8902 - accuracy: 0.6528 - val_loss: 3.0767 - val_accuracy: 0.6406\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0781 - val_accuracy: 0.6406\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8898 - accuracy: 0.6545 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8898 - accuracy: 0.6545 - val_loss: 3.0763 - val_accuracy: 0.6406\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8901 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0808 - val_accuracy: 0.6406\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6528 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8900 - accuracy: 0.6545 - val_loss: 3.0803 - val_accuracy: 0.6406\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8901 - accuracy: 0.6528 - val_loss: 3.0782 - val_accuracy: 0.6406\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0787 - val_accuracy: 0.6406\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8898 - accuracy: 0.6545 - val_loss: 3.0778 - val_accuracy: 0.6406\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0794 - val_accuracy: 0.6406\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8899 - accuracy: 0.6545 - val_loss: 3.0776 - val_accuracy: 0.6406\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0810 - val_accuracy: 0.6406\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0791 - val_accuracy: 0.6406\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0771 - val_accuracy: 0.6406\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.0834 - val_accuracy: 0.6406\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0787 - val_accuracy: 0.6406\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6528 - val_loss: 3.0779 - val_accuracy: 0.6406\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0762 - val_accuracy: 0.6406\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.0814 - val_accuracy: 0.6406\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.0802 - val_accuracy: 0.6406\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8902 - accuracy: 0.6545 - val_loss: 3.0813 - val_accuracy: 0.6406\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0817 - val_accuracy: 0.6406\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0797 - val_accuracy: 0.6406\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.0770 - val_accuracy: 0.6406\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.0790 - val_accuracy: 0.6406\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.0802 - val_accuracy: 0.6406\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0786 - val_accuracy: 0.6406\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.0777 - val_accuracy: 0.6406\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0806 - val_accuracy: 0.6406\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0814 - val_accuracy: 0.6406\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0897 - val_accuracy: 0.6406\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6528 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0800 - val_accuracy: 0.6406\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.0813 - val_accuracy: 0.6406\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.0831 - val_accuracy: 0.6406\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6528 - val_loss: 3.0843 - val_accuracy: 0.6406\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.0840 - val_accuracy: 0.6406\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.0782 - val_accuracy: 0.6406\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0791 - val_accuracy: 0.6406\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8896 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0778 - val_accuracy: 0.6406\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.0835 - val_accuracy: 0.6406\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6528 - val_loss: 3.0808 - val_accuracy: 0.6406\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8895 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.0877 - val_accuracy: 0.6406\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6528 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8890 - accuracy: 0.6528 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0820 - val_accuracy: 0.6406\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8894 - accuracy: 0.6528 - val_loss: 3.0807 - val_accuracy: 0.6406\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.0862 - val_accuracy: 0.6406\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.0790 - val_accuracy: 0.6406\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.0830 - val_accuracy: 0.6406\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.0793 - val_accuracy: 0.6406\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8888 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8888 - accuracy: 0.6528 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.0795 - val_accuracy: 0.6406\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8891 - accuracy: 0.6528 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.0866 - val_accuracy: 0.6406\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8892 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8890 - accuracy: 0.6528 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8884 - accuracy: 0.6528 - val_loss: 3.0773 - val_accuracy: 0.6406\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8897 - accuracy: 0.6545 - val_loss: 3.0786 - val_accuracy: 0.6406\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8893 - accuracy: 0.6545 - val_loss: 3.0808 - val_accuracy: 0.6406\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1083 - val_accuracy: 0.6406\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8888 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.0861 - val_accuracy: 0.6406\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8888 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8884 - accuracy: 0.6545 - val_loss: 3.0836 - val_accuracy: 0.6406\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.0766 - val_accuracy: 0.6406\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8884 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8894 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.0798 - val_accuracy: 0.6406\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8888 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.0806 - val_accuracy: 0.6406\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8888 - accuracy: 0.6528 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8888 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8891 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.0795 - val_accuracy: 0.6406\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1071 - val_accuracy: 0.6406\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1089 - val_accuracy: 0.6406\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8888 - accuracy: 0.6528 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8884 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8887 - accuracy: 0.6528 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1085 - val_accuracy: 0.6406\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.0789 - val_accuracy: 0.6406\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8889 - accuracy: 0.6545 - val_loss: 3.0816 - val_accuracy: 0.6406\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8884 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8883 - accuracy: 0.6545 - val_loss: 3.0821 - val_accuracy: 0.6406\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8887 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8890 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8886 - accuracy: 0.6545 - val_loss: 3.1071 - val_accuracy: 0.6406\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8884 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1085 - val_accuracy: 0.6406\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8883 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6528 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1088 - val_accuracy: 0.6406\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8883 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6528 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1092 - val_accuracy: 0.6406\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8881 - accuracy: 0.6528 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8881 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8878 - accuracy: 0.6528 - val_loss: 3.1088 - val_accuracy: 0.6406\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8882 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1085 - val_accuracy: 0.6406\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8869 - accuracy: 0.6545 - val_loss: 3.0792 - val_accuracy: 0.6406\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8883 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8876 - accuracy: 0.6528 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1094 - val_accuracy: 0.6406\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1072 - val_accuracy: 0.6406\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.0862 - val_accuracy: 0.6406\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8885 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8879 - accuracy: 0.6545 - val_loss: 3.1083 - val_accuracy: 0.6406\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8874 - accuracy: 0.6528 - val_loss: 3.1073 - val_accuracy: 0.6406\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1090 - val_accuracy: 0.6406\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8880 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8877 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1082 - val_accuracy: 0.6406\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8874 - accuracy: 0.6528 - val_loss: 3.1083 - val_accuracy: 0.6406\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1082 - val_accuracy: 0.6406\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8874 - accuracy: 0.6545 - val_loss: 3.1082 - val_accuracy: 0.6406\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8870 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8875 - accuracy: 0.6528 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.8876 - accuracy: 0.6545 - val_loss: 3.1084 - val_accuracy: 0.6406\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8876 - accuracy: 0.6528 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6528 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1082 - val_accuracy: 0.6406\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8877 - accuracy: 0.6528 - val_loss: 3.1077 - val_accuracy: 0.6406\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8869 - accuracy: 0.6545 - val_loss: 3.1090 - val_accuracy: 0.6406\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8870 - accuracy: 0.6545 - val_loss: 3.1095 - val_accuracy: 0.6406\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1083 - val_accuracy: 0.6406\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8869 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8872 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8878 - accuracy: 0.6545 - val_loss: 3.1079 - val_accuracy: 0.6406\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1078 - val_accuracy: 0.6406\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8870 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1086 - val_accuracy: 0.6406\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8872 - accuracy: 0.6528 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8875 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8869 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8868 - accuracy: 0.6545 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1090 - val_accuracy: 0.6406\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8868 - accuracy: 0.6545 - val_loss: 3.1074 - val_accuracy: 0.6406\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8868 - accuracy: 0.6545 - val_loss: 3.1085 - val_accuracy: 0.6406\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8868 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8873 - accuracy: 0.6528 - val_loss: 3.1080 - val_accuracy: 0.6406\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1076 - val_accuracy: 0.6406\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8871 - accuracy: 0.6545 - val_loss: 3.1075 - val_accuracy: 0.6406\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8869 - accuracy: 0.6545 - val_loss: 3.1081 - val_accuracy: 0.6406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "auDowND4DGtB",
        "outputId": "791caba6-5a1c-4d6d-812e-26a48c0ae5a5"
      },
      "id": "auDowND4DGtB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ce35defc6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Interpret results\n",
        "The results shows in the graph that the model is underfitting since the gap between the two losses are high. It shows that under 200 epoch the model are good fit indicating that having 200 epoch is enough."
      ],
      "metadata": {
        "id": "TR5w_41VJYxk"
      },
      "id": "TR5w_41VJYxk"
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the roc curve for the predictions\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "NxBrpwX4FVRa",
        "outputId": "be9dab89-501b-4f2f-f694-879befba7e9b"
      },
      "id": "NxBrpwX4FVRa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.760\n",
            "roc-auc is 0.818\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use different learning rates, numbers of epochs, and network structures.\n",
        "model_2 = Sequential([\n",
        "    Dense(10, input_shape=(8,), activation=\"tanh\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "7_XdW9FoFZty"
      },
      "id": "7_XdW9FoFZty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kistrKvqGIUB",
        "outputId": "507ca622-9748-494a-ecd9-73896ac67b40"
      },
      "id": "kistrKvqGIUB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101 (404.00 Byte)\n",
            "Trainable params: 101 (404.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the results of training and validation loss using different learning rates, number of epochs and network structures\n",
        "model_2.compile(SGD(lr = .005), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YzVdXJoFeiZ",
        "outputId": "73d925d7-01d8-4ac5-d48e-3d11f2cdbb8f"
      },
      "id": "3YzVdXJoFeiZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6533 - accuracy: 0.6319 - val_loss: 0.6636 - val_accuracy: 0.6406\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.6806 - val_loss: 0.6425 - val_accuracy: 0.6510\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7101 - val_loss: 0.6248 - val_accuracy: 0.6979\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5962 - accuracy: 0.7222 - val_loss: 0.6100 - val_accuracy: 0.6979\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7361 - val_loss: 0.5975 - val_accuracy: 0.7135\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7344 - val_loss: 0.5868 - val_accuracy: 0.7188\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7413 - val_loss: 0.5775 - val_accuracy: 0.7135\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7448 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7500 - val_loss: 0.5625 - val_accuracy: 0.7240\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7517 - val_loss: 0.5564 - val_accuracy: 0.7188\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7483 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7483 - val_loss: 0.5463 - val_accuracy: 0.7135\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.7517 - val_loss: 0.5421 - val_accuracy: 0.7083\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7604 - val_loss: 0.5383 - val_accuracy: 0.7083\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7639 - val_loss: 0.5349 - val_accuracy: 0.7135\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7656 - val_loss: 0.5319 - val_accuracy: 0.7188\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7639 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7656 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7188\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7708 - val_loss: 0.5224 - val_accuracy: 0.7188\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7188\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7726 - val_loss: 0.5173 - val_accuracy: 0.7188\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7188\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7760 - val_loss: 0.5145 - val_accuracy: 0.7188\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7188\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7240\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7795 - val_loss: 0.5111 - val_accuracy: 0.7188\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7812 - val_loss: 0.5102 - val_accuracy: 0.7188\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7188\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7188\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7188\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7188\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7188\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7240\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7292\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7795 - val_loss: 0.5046 - val_accuracy: 0.7292\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7344\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7344\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7344\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7344\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7396\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7396\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.5006 - val_accuracy: 0.7396\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7396\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7396\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.4996 - val_accuracy: 0.7448\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7448\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.4991 - val_accuracy: 0.7448\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7448\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.4988 - val_accuracy: 0.7448\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.4987 - val_accuracy: 0.7448\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7448\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4983 - val_accuracy: 0.7448\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7448\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7795 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7448\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7812 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7500\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7882 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7500\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4979 - val_accuracy: 0.7500\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.4980 - val_accuracy: 0.7500\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7500\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7812 - val_loss: 0.4983 - val_accuracy: 0.7500\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7795 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7795 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7760 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7760 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7795 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7500\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7760 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7778 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7778 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7726 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7778 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7778 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7778 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7500\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7778 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 318/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 319/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 320/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 321/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 322/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 323/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 324/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 325/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 326/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
            "Epoch 327/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
            "Epoch 328/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 329/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
            "Epoch 330/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
            "Epoch 331/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 332/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 333/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 334/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 335/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
            "Epoch 336/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 337/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 338/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 339/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 340/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 341/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
            "Epoch 342/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 343/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 344/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 345/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 346/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 347/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 348/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 349/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 350/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 351/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 352/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 353/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 354/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 355/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 356/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 357/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 358/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 359/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 360/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 361/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 362/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 363/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 364/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 365/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 366/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 367/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
            "Epoch 368/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 369/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 370/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 371/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 372/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
            "Epoch 373/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 374/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 375/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 376/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
            "Epoch 377/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 378/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 379/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 380/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 381/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 382/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7778 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 383/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 384/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 385/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 386/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 387/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 388/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 389/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 390/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 391/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 392/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 393/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7778 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 394/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7396\n",
            "Epoch 395/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 396/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 397/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 398/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7778 - val_loss: 0.5081 - val_accuracy: 0.7396\n",
            "Epoch 399/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 400/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 401/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 402/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.5082 - val_accuracy: 0.7396\n",
            "Epoch 403/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 404/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 405/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 406/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
            "Epoch 407/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 408/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 409/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 410/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
            "Epoch 411/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 412/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 413/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 414/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 415/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
            "Epoch 416/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 417/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 418/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 419/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 420/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 421/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 422/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 423/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 424/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 425/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7778 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 426/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 427/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 428/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7396\n",
            "Epoch 429/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 430/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 431/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 432/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7396\n",
            "Epoch 433/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7760 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 434/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7760 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 435/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
            "Epoch 436/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 437/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 438/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 439/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7396\n",
            "Epoch 440/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 441/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 442/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 443/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7396\n",
            "Epoch 444/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 445/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 446/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 447/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7396\n",
            "Epoch 448/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
            "Epoch 449/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
            "Epoch 450/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
            "Epoch 451/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7396\n",
            "Epoch 452/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
            "Epoch 453/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
            "Epoch 454/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
            "Epoch 455/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7396\n",
            "Epoch 456/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
            "Epoch 457/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
            "Epoch 458/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
            "Epoch 459/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
            "Epoch 460/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
            "Epoch 461/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
            "Epoch 462/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
            "Epoch 463/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
            "Epoch 464/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
            "Epoch 465/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
            "Epoch 466/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7795 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
            "Epoch 467/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
            "Epoch 468/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7795 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
            "Epoch 469/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
            "Epoch 470/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
            "Epoch 471/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 472/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 473/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 474/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 475/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7795 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 476/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7795 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 477/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 478/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7812 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 479/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 480/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 481/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 482/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 483/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 484/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 485/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 486/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 487/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 488/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 489/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 490/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 491/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 492/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 493/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 494/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 495/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 496/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 497/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 498/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 499/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 500/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.5109 - val_accuracy: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Z9SqoF8-HlKi",
        "outputId": "7e6a35a1-c7be-43cd-85f4-a435ff2c6430"
      },
      "id": "Z9SqoF8-HlKi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ce35dbe9f00>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Interpret your result\n",
        "\n",
        "It shows that the experimented one is good fit since both are stabilizing as the epoch gets higher. The results shows stablization as the epoch gets further."
      ],
      "metadata": {
        "id": "QLHp_GB_IFBs"
      },
      "id": "QLHp_GB_IFBs"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "To conclude, this activity help me understand on how to train neural networks and how to apply it into deep learning and how to use it in models. Although I experienced some errors, I still tried to solve it and I think I solved it somehow and as the time goes by and everytime I tried to fix the errors I realized what this hands-on activity for and how this works. Lastly, this activity help me to have a better idea how cool deep learning is and how important it is."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "njmK8NnBZTcH"
      },
      "id": "njmK8NnBZTcH"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4krV6c4cZTtg"
      },
      "id": "4krV6c4cZTtg"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VxL0tjW4ZUAg"
      },
      "id": "VxL0tjW4ZUAg"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LdCZW_ZxZUOo"
      },
      "id": "LdCZW_ZxZUOo"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L-0sbkIiZUbX"
      },
      "id": "L-0sbkIiZUbX"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bpDAneciZUt3"
      },
      "id": "bpDAneciZUt3"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CPnbWxEnZYe4"
      },
      "id": "CPnbWxEnZYe4"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EeIXw_LTZYPo"
      },
      "id": "EeIXw_LTZYPo"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "43AC2-hzZX13"
      },
      "id": "43AC2-hzZX13"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}